{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gym import Env\n",
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "from gym.spaces import Discrete, Box\n",
    "import numpy as np\n",
    "import random\n",
    "import pygame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainEnv(Env):\n",
    "    metadata = {'render.modes': ['human']}\n",
    "    \n",
    "    def __init__(self):\n",
    "        # Actions: accelerate, slow down, keep speed\n",
    "        self.action_space = Discrete(3)\n",
    "        # Store current speed, position x, position y, distance left\n",
    "        self.observation_space = Box(low=np.array([0.0, 0.0, 0.0, 0.0]), high=np.array([1.0, 1000.0, 768.0, 20000.0]))\n",
    "\n",
    "        # Initial state: [speed, x, y, distance_left]\n",
    "        self.state = [0.0, 118.0, 110.0, 767.0]\n",
    "        self.target = np.array([885, 110])\n",
    "\n",
    "        # Initialize variables for Pygame\n",
    "        self.screen = None\n",
    "        self.clock = None\n",
    "        self.is_pygame_initialized = False  # Flag to check if Pygame is initialized\n",
    "\n",
    "        self.init_pygame()\n",
    "\n",
    "    def init_pygame(self):\n",
    "        print(\"Initializing Pygame...\")\n",
    "        pygame.init() \n",
    "        self.screen = pygame.display.set_mode((1000, 768))\n",
    "        self.clock = pygame.time.Clock()\n",
    "        self.is_pygame_initialized = True\n",
    "\n",
    "        # Initialize font\n",
    "        pygame.font.init()\n",
    "        self.font = pygame.font.Font(None, 36)\n",
    "\n",
    "    def step(self, action):\n",
    "        reward = 0\n",
    "        speed, x, y, distance_left = self.state\n",
    "        current_position = np.array([x, y])\n",
    "        direction = self.target - current_position\n",
    "        distance_to_target = np.linalg.norm(direction)\n",
    "        \n",
    "        # Constants\n",
    "        max_speed = 1.0  # Maximum speed\n",
    "        max_acceleration = 0.005  # Maximum speed increase per step\n",
    "        max_deceleration = 0.005  # Maximum speed decrease per step\n",
    "\n",
    "        # Action: 0 = accelerate, 1 = decelerate, 2 = maintain speed\n",
    "        if action == 0:  # Accelerate\n",
    "            speed = min(max_speed, speed + max_acceleration)\n",
    "        elif action == 1:  # Decelerate\n",
    "            speed = max(0.0, speed - max_deceleration)\n",
    "        # maintain speed requires no change\n",
    "\n",
    "        # Move the train\n",
    "        direction_unit = direction / distance_to_target if distance_to_target > 0 else np.array([0, 0])\n",
    "        new_position = current_position + speed * direction_unit\n",
    "        self.state = [speed, new_position[0], new_position[1], distance_to_target]\n",
    "\n",
    "        if speed > 0.9 * max_speed:\n",
    "            reward += 0.1  # Reward for maintaining high speed\n",
    "        else:\n",
    "            reward -= 0.1  # Time penalty for taking too long\n",
    "        if distance_to_target < 5:\n",
    "            if speed < 0.1:\n",
    "                reward += 100\n",
    "            else:\n",
    "                reward -= 100\n",
    "            done = True\n",
    "        else:\n",
    "            done = False\n",
    "\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = [0.0, 118.0, 110.0, 767.0]\n",
    "        return self.state\n",
    "\n",
    "    def render(self, mode='human'):\n",
    "        # Clear the screen\n",
    "        self.screen.fill((0, 0, 0))\n",
    "\n",
    "        # Draw the target\n",
    "        pygame.draw.circle(self.screen, (255, 0, 0), (int(self.target[0]), int(self.target[1])), 10)\n",
    "\n",
    "        # Draw the train (as a small circle)\n",
    "        train_position = (int(self.state[1]), int(self.state[2]))\n",
    "        pygame.draw.circle(self.screen, (0, 255, 0), train_position, 10)\n",
    "\n",
    "        speed_text = self.font.render(f\"Speed: {self.state[0]:.2f}\", True, (255, 255, 255))\n",
    "        # Blit the text onto the screen\n",
    "        self.screen.blit(speed_text, (10, 10))  \n",
    "\n",
    "        # Update the display\n",
    "        pygame.display.flip()\n",
    "\n",
    "        # Cap the frame rate\n",
    "        self.clock.tick(60)\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        if self.is_pygame_initialized:\n",
    "            print(\"Closing Pygame...\")\n",
    "            pygame.quit()\n",
    "            self.is_pygame_initialized = False\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\benat\\anaconda3\\Lib\\site-packages\\tensorflow\\python\\debug\\cli\\debugger_cli_common.py:19: DeprecationWarning: module 'sre_constants' is deprecated\n",
      "  import sre_constants\n",
      "c:\\Users\\benat\\anaconda3\\Lib\\site-packages\\tensorflow\\lite\\python\\util.py:52: DeprecationWarning: jax.xla_computation is deprecated. Please use the AOT APIs.\n",
      "  from jax import xla_computation as _xla_computation\n",
      "c:\\Users\\benat\\anaconda3\\Lib\\site-packages\\botocore\\utils.py:15: DeprecationWarning: 'cgi' is deprecated and slated for removal in Python 3.13\n",
      "  import cgi\n",
      "c:\\Users\\benat\\anaconda3\\Lib\\site-packages\\botocore\\httpsession.py:41: DeprecationWarning: 'urllib3.contrib.pyopenssl' module is deprecated and will be removed in a future release of urllib3 2.x. Read more in this issue: https://github.com/urllib3/urllib3/issues/2680\n",
      "  from urllib3.contrib.pyopenssl import orig_util_SSLContext as SSLContext\n",
      "c:\\Users\\benat\\anaconda3\\Lib\\site-packages\\gym\\spaces\\box.py:128: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  logger.warn(f\"Box bound precision lowered by casting to {self.dtype}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Pygame...\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from keras.optimizers import Adam  # Change made here\n",
    "from rl.agents import DQNAgent\n",
    "from rl.policy import BoltzmannQPolicy\n",
    "from rl.memory import SequentialMemory\n",
    "\n",
    "# Environment test\n",
    "env = TrainEnv()\n",
    "\n",
    "states = env.observation_space.shape[0]\n",
    "actions = env.action_space.n\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(1, states)))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(24, activation=\"relu\"))\n",
    "model.add(Dense(actions, activation=\"linear\"))\n",
    "\n",
    "agent = DQNAgent(\n",
    "    model=model,\n",
    "    memory=SequentialMemory(limit=50000, window_length=1),\n",
    "    nb_actions=actions,\n",
    "    nb_steps_warmup=10,\n",
    "    target_model_update=0.01,\n",
    "    enable_double_dqn=True\n",
    ")\n",
    "agent.compile(Adam(learning_rate=0.001), metrics=[\"mae\"]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run only for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.fit(env, nb_steps=100000, visualize=False, verbose=1)\n",
    "# results = agent.test(env, nb_episodes=10, visualize=False)\n",
    "# print(np.mean(results.history))\n",
    "\n",
    "# Save the model weights after training\n",
    "agent.save_weights('dqn_trainenv_weights.h5f', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Render and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing Pygame...\n",
      "Quitting Pygame...\n",
      "Closing Pygame...\n",
      "Total reward: -7.499999999999989\n"
     ]
    }
   ],
   "source": [
    "# Assuming the agent has been trained and saved\n",
    "agent.load_weights('dqn_trainenv_weights.h5f')\n",
    "env = TrainEnv()\n",
    "# Visualize one episode with the trained agent\n",
    "state = env.reset()\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "\n",
    "    for event in pygame.event.get():\n",
    "        if event.type == pygame.QUIT or (event.type == pygame.KEYDOWN and event.key == pygame.K_ESCAPE):\n",
    "            print(\"Quitting Pygame...\")\n",
    "            env.close()  # Call close method to quit Pygame and stop the simulation\n",
    "            done = True\n",
    "            break\n",
    "\n",
    "    if done:  # Break the loop if quitting was triggered\n",
    "        break\n",
    "                \n",
    "    action = agent.forward(state)\n",
    "    state, reward, done, _ = env.step(action)\n",
    "\n",
    "    # Render the environment with Pygame\n",
    "    env.render()\n",
    "\n",
    "    total_reward += reward\n",
    "\n",
    "print(f\"Total reward: {total_reward}\")\n",
    "env.close()  # Ensure to close Pygame when done\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
